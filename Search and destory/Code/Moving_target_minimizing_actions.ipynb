{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MovingTarget_Part4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_od6s7osAmCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sapssOd8HX_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "import time\n",
        "import pprint as pp\n",
        "import pandas as pd\n",
        "from operator import itemgetter\n",
        "from matplotlib.colors import ListedColormap\n",
        "from matplotlib.patches import Rectangle\n",
        "import pdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiN2yZZw6ZFG",
        "colab_type": "text"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKMqYD3t6Lco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def place_target(env_terrains):\n",
        "  a = env_terrains.shape[0] - 1\n",
        "\n",
        "  i = random.randint(0,a)\n",
        "  j = random.randint(0,a)\n",
        "\n",
        "  return((i, j))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG3zUW346YBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_environment(a):\n",
        "\n",
        "  env_terrains = np.zeros((a,a))\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      terrain = random.random()\n",
        "      \n",
        "      if terrain < 0.2:\n",
        "        env_terrains[i, j] = 5 # Flat terrain with p = 0.2\n",
        "      elif terrain < 0.5:\n",
        "        env_terrains[i, j] = 10 # Hilly terrain with p = 0.3\n",
        "      elif terrain < 0.8:\n",
        "        env_terrains[i, j] = 15 # Forested terrain with p = 0.3\n",
        "      else:\n",
        "        env_terrains[i, j] = 20 # Maze of caves with p = 0.2\n",
        "  \n",
        "  target_location = place_target(env_terrains)\n",
        "  environment = (env_terrains, target_location)\n",
        "  return environment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gBe10E46fYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def display_grid(environment):\n",
        "  env_grid = environment[0]\n",
        "  target_location = environment[1]\n",
        "\n",
        "  plt.figure(figsize = (8, 8))\n",
        "  color_list = ['lightgreen', 'darkgreen']\n",
        "  palette = sns.color_palette(color_list)\n",
        "  ax = sns.heatmap(env_grid, annot = True,  linewidths = 0.01, linecolor = 'darkgray', cbar = False, xticklabels = True, yticklabels = True)\n",
        "  ax.add_patch(Rectangle((target_location[1], target_location[0]), 1, 1, fill= False, capstyle = 'projecting', edgecolor='gold', linewidth = 4))\n",
        "  plt.text(target_location[1] + 0.5, target_location[0] + 0.5, 'x', horizontalalignment = 'center', verticalalignment = 'center', fontsize = 30, color = 'gold')\n",
        "  b, t = plt.ylim() # discover the values for bottom and top\n",
        "  b += 0.5 # Add 0.5 to the bottom\n",
        "  t -= 0.5 # Subtract 0.5 from the top\n",
        "  plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9UUpCnB6hcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def search_cell(environment, cell):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  target_location = environment[1]\n",
        "\n",
        "  if cell != target_location:\n",
        "    return False\n",
        "\n",
        "  else:\n",
        "    if env_grid[cell] == 5:\n",
        "      if random.random() < 0.9:\n",
        "        return True\n",
        "    elif env_grid[cell] == 10:\n",
        "      if random.random() < 0.7:\n",
        "        return True\n",
        "    elif env_grid[cell] == 15:\n",
        "      if random.random() < 0.3:\n",
        "        return True\n",
        "    elif env_grid[cell] == 20:\n",
        "      if random.random() < 0.1:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtBrX6X96tqx",
        "colab_type": "text"
      },
      "source": [
        "#####Moving Target implementation in environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcq6JSGG6hhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_child_validity(a, cell):\n",
        "    # If dimensions are in the range of the matrix dimensions (if cell is going out of bounds)\n",
        "    if cell[0] == -1 or cell[1] == -1 or cell[0] == a or cell[1] == a:\n",
        "        return False\n",
        "    # Valid\n",
        "    else:\n",
        "        return True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgljoM8t6hk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def move_target(a, cell):\n",
        "  \n",
        "  i = cell[0]\n",
        "  j = cell[1]\n",
        "  neighbors = [(i - 1, j), (i , j - 1), (i , j + 1), (i + 1, j )]\n",
        "  valid_neighbor = []\n",
        "\n",
        "  for neighbor in neighbors:\n",
        "    if(check_child_validity(a,neighbor)):\n",
        "      valid_neighbor.append(neighbor)\n",
        "  \n",
        "  n = len(valid_neighbor)\n",
        "  return valid_neighbor[random.randint(0,n-1)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6lgcSu86hr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tracker(environment):\n",
        "\n",
        "#changing the target location and reflecting it in the environment\n",
        "  a = environment[0].shape[0]\n",
        "  curret_target_location = environment[1]\n",
        "  new_target_location = move_target( a, curret_target_location )\n",
        "  #print(new_target_location)\n",
        "  environment = (environment[0], new_target_location)  \n",
        "  \n",
        "#report terrain type where target is not loacted. \n",
        "  terrain_of_target = terrain_type(environment, new_target_location)\n",
        "  not_target = list(set([0,1,2,3]) - set([terrain_of_target]))\n",
        "  t = random.randint(0,2)\n",
        "  report_terrain = not_target[t]\n",
        "\n",
        "  return environment, report_terrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxLO7s_R6n-L",
        "colab_type": "text"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5y6rrUB6o5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rule_1(belief_map):\n",
        "  cell_index = np.unravel_index(np.argmax(belief_map, axis=None), belief_map.shape)\n",
        "  return cell_index\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbZAU67f67Y4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rule_2(environment, belief_map, false_negative_rate):\n",
        "  \n",
        "  false_negative_matrix = environment[0]/5\n",
        "  for x in range(1,5):\n",
        "   false_negative_matrix[false_negative_matrix == x] = (1 - false_negative_rate[x-1])\n",
        "\n",
        "  new_probability = np.multiply(false_negative_matrix, belief_map)\n",
        "  cell_index = np.unravel_index(np.random.choice(np.flatnonzero(new_probability == new_probability.max())), belief_map.shape)\n",
        "  return cell_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJKbqQI1DEIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_belief(environment, prior_belief_map, cell_opened, false_negative_rate):\n",
        "    \n",
        "    dim = environment[0].shape[0]\n",
        "    terrain = np.int(environment[0][cell_opened]/5)-1\n",
        "    false_negative_cell_opened = false_negative_rate[terrain]\n",
        "    \n",
        "    denominator = (prior_belief_map[cell_opened] * (1 - false_negative_cell_opened)) + (1 - prior_belief_map[cell_opened])\n",
        "\n",
        "    update_belief_map = prior_belief_map/denominator\n",
        "    update_belief_map[cell_opened] = update_belief_map[cell_opened] * (1 - false_negative_cell_opened)\n",
        "\n",
        "    return update_belief_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYf8D0ej67g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def terrain_type(environment, cell):\n",
        "  return np.int(environment[0][cell]/5)-1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_PoOJXs67mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neighbor_information(a):\n",
        "\n",
        "  ## count of neighbours of each cell\n",
        "\n",
        "  count_neighbor_mat = np.full((a,a),4)\n",
        "\n",
        "  for j in range(1,a-1):\n",
        "    count_neighbor_mat[0, j] = 3\n",
        "    count_neighbor_mat[a-1, j] = 3\n",
        "    count_neighbor_mat[j, 0] = 3\n",
        "    count_neighbor_mat[j, a-1] = 3\n",
        "\n",
        "  count_neighbor_mat[0][0] = 2\n",
        "  count_neighbor_mat[0][a-1] = 2\n",
        "  count_neighbor_mat[a-1][0] = 2\n",
        "  count_neighbor_mat[a-1][a-1] = 2\n",
        "\n",
        "\n",
        "  ## list of valid neighbours for each cell \n",
        "\n",
        "  valid_neighbor = [[[] for i in range(a)] for j in range(a)]\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      neighbors = [(i - 1, j), (i , j - 1), (i , j + 1), (i + 1, j )]\n",
        "      for neighbor in neighbors:\n",
        "        if(check_child_validity(a,neighbor)):\n",
        "          valid_neighbor[i][j].append(neighbor)\n",
        "\n",
        "  return (count_neighbor_mat, valid_neighbor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZROdPuz67p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def belief_updade_given_failure(prior_belief_map, neighbor_info_map):\n",
        " ##################################################################################################################################################################\n",
        "  # P( target in cell i at t+1 | observation at t)                                                                                                                 #\n",
        "  #           = (summation over all j = neighbours of i) [ P(target in cell j at t | observations at t) * P (target in cell i at t+1 | target in cell j at t+1)  ] #\n",
        "  #           = (summation over all j = neighbours of i) [ P(target in cell j at t | observations at t) * (1/ No. of Negibours of j) ]                             #\n",
        "  ##################################################################################################################################################################\n",
        "\n",
        "  a = prior_belief_map.shape[0]\n",
        "  neigbor_count = neighbor_info_map[0]\n",
        "  valid_neighbor = neighbor_info_map[1]\n",
        "\n",
        "  updated_belief_map = np.empty((a,a))\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      \n",
        "      prob_sum = 0\n",
        "      n_neighbors = neigbor_count[(i,j)]\n",
        "      for n in range(np.int(n_neighbors)):\n",
        "        neighbor = valid_neighbor[i][j][n]\n",
        "        prob_sum = prob_sum + prior_belief_map[neighbor]\n",
        "\n",
        "      updated_belief_map[(i,j)] = prob_sum /  n_neighbors\n",
        "\n",
        "  return updated_belief_map\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7nS5y3L67s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def terrain_type_total(environment, terrain):\n",
        "\n",
        "  env_grid = (environment[0]/5 - 1).astype(int)\n",
        "  counts = np.bincount(env_grid.flatten())\n",
        "\n",
        "  return sum(counts) - counts[terrain]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAFELsim67x5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def belief_update_given_tracker_info(environment, prior_belief_map, target_not_in_terrain):\n",
        "\n",
        "  ##########################################################################################################################################################\n",
        "  # P( target in cell i at t+1 | observation at t, target not in terrain T at t+1)                                                                            #\n",
        "  #     =  P( target in cell i at t+1 | observation at t) * P(target not in terrain T at t+1 | observation at t, target in cell i at t+1  )                   #\n",
        "  #        ---------------------------------------------------------------------------------------------------------------------------------                  #\n",
        "  #                                                P(target not in terrain T at t+1 | observation at t)                                                       #\n",
        "  #                                                                                                                                                           #\n",
        "  #     =   Prior * [ 0  if terrain of target cell i = target_not_in_terrain,   1/3 else ]                                                                    #\n",
        "  #        --------------------------------------------------------------------------------                                                                   #\n",
        "  #               P(target not in terrain T at t+1 | observation at t)\n",
        "  #\n",
        "  #\n",
        "  #\n",
        "  # P(target not in terrain T at t+1 | observation at t) \n",
        "  #           = P(target in cell i at t+1  | observation at t) * P(target not in terrain T at t+1 | observation at t, target in cell i at t+1 )\n",
        "  #              + P(target not in cell i at t+1  | observation at t) * P(target not in terrain T at t+1 | observation at t, target not in cell i at t+1  )\n",
        "  #           =  Prior * [ 0  if terrain of target cell i = target_not_in_terrain,   1/3 else ] \n",
        "  #              + (1 - Prior) * P(target not in terrain T at t+1 | observation at t, target not in cell i at t+1  )\n",
        "  #\n",
        "  #############################################################################################################################################################\n",
        "  a = prior_belief_map.shape[0]\n",
        "  updated_belief_map = np.empty((a,a))\n",
        "  n_not_terrain = terrain_type_total( environment, target_not_in_terrain)\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      cell = (i,j)\n",
        "      terrain_cell = terrain_type(environment, cell)\n",
        "      \n",
        "      if(terrain_cell == target_not_in_terrain):\n",
        "        p = 0\n",
        "        x = n_not_terrain / (a*a - 1)\n",
        "      else:\n",
        "        p = 1/3\n",
        "        x = (n_not_terrain - 1) / (a*a - 1)\n",
        "\n",
        "      denominator = (prior_belief_map[cell] * p) + ((1 - prior_belief_map[cell]) * x)\n",
        "      updated_belief_map[cell] = (prior_belief_map[cell] * p)/denominator\n",
        "  \n",
        "  return updated_belief_map"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8TjFStsCcLu",
        "colab_type": "text"
      },
      "source": [
        "#####Compute Cost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB5r0FZ4eX5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_actions(current_cell, target_cell):\n",
        "  # +1 for searching it\n",
        "  return abs(current_cell[0]- target_cell[0]) + abs(current_cell[1]- target_cell[1]) + 1 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnca96pv_4HO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost_one_step(environment, belief_map, current_cell, false_negative_rate):\n",
        "  \n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "  min_cost_so_far = float('inf')\n",
        "  cell_with_min_cost = (0,0)\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      # manhattan_distance\n",
        "      distance = abs(current_cell[0]-i) + abs(current_cell[1]-j)\n",
        "      terrain = np.int(env_grid[(i,j)]/5)-1\n",
        "      false_negative_cell_opened = false_negative_rate[terrain]\n",
        "      if belief_map[i][j] != 0:\n",
        "        # cost = distance + (math.sqrt(1/(belief_map[i][j]*(1-false_negative_cell_opened)))) \n",
        "        cost = distance/(2 * a) + (1 - (belief_map[i][j]*(1 - false_negative_cell_opened))) + 1\n",
        "        # cost = (distance/(belief_map[i][j] * (1 - false_negative_cell_opened))) + 1\n",
        "        if(min_cost_so_far > cost):\n",
        "          min_cost_so_far = cost\n",
        "          cell_with_min_cost = (i,j)\n",
        "\n",
        "  actions =  compute_actions(current_cell, cell_with_min_cost)   \n",
        "\n",
        "  return cell_with_min_cost, actions, min_cost_so_far"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxKFuc63Jf-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def simplified_two_step_cost(environment, belief_map, current_cell, false_negative_rate):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "\n",
        "  min_cost_so_far = float('inf')\n",
        "  min_first_cell = (0,0)\n",
        "  min_second_cell = (0,0)\n",
        "  \n",
        "  cost_matrix = np.full((a,a), 10000.0)\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      if(i!=current_cell[0] or j!=current_cell[1]):\n",
        "        first_cell = (i,j)\n",
        "        distance_from_current_to_first = abs(current_cell[0]-i) + abs(current_cell[1]-j)\n",
        "        terrain = np.int(env_grid[first_cell]/5)-1\n",
        "        false_negative_cell_opened = false_negative_rate[terrain]\n",
        "        ## Cost from current cell to first cell (i,j)\n",
        "        cost_1 = distance_from_current_to_first/ (2 * a) + 1 \n",
        "        p_1 = 1 - (belief_map[first_cell]*(1 - false_negative_cell_opened))\n",
        "        temp_belief_map = np.full((a,a), 0)\n",
        "        temp_belief_map = update_belief(environment, belief_map, first_cell, false_negative_rate)\n",
        "        min_cell, min_actions, min_cost = compute_cost_one_step(environment, temp_belief_map, first_cell, false_negative_rate)\n",
        "        total_expected_cost = cost_1 + p_1*min_cost\n",
        "\n",
        "        if(min_cost_so_far > total_expected_cost):\n",
        "          min_cost_so_far = total_expected_cost\n",
        "\n",
        "        cost_matrix[(i, j)] = round(total_expected_cost,2)\n",
        "\n",
        "  min_first_cell = np.unravel_index(np.random.choice(np.flatnonzero(cost_matrix == cost_matrix.min())), cost_matrix.shape)\n",
        "  # print(\"Min_cost = \", cost_matrix[min_first_cell])\n",
        "  # print(\"First cell = \", min_first_cell )\n",
        "  # print(\"Cost Matrix:\")\n",
        "  # pp.pprint(cost_matrix)\n",
        "  # display_grid((cost_matrix, min_first_cell))\n",
        "  actions = compute_actions(current_cell, min_first_cell)\n",
        "  return min_first_cell, actions, min_cost_so_far"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dsn9rcY4h9d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost_two_steps(environment, belief_map, current_cell, false_negative_rate):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "\n",
        "  min_cost_so_far = float('inf')\n",
        "  min_first_cell = (0,0)\n",
        "  min_second_cell = (0,0)\n",
        "  \n",
        "  cost_matrix = np.full((a,a), 10000.0)\n",
        "  second_cells = [[(-1, -1) for i in range(a)] for j in range(a)]\n",
        "\n",
        "  for i in range(a):\n",
        "    for j in range(a):\n",
        "      if(i!=current_cell[0] or j!=current_cell[1]):\n",
        "        first_cell = (i,j)\n",
        "        distance_from_current_to_first = abs(current_cell[0]-i) + abs(current_cell[1]-j)\n",
        "        terrain = np.int(env_grid[first_cell]/5)-1\n",
        "        false_negative_cell_opened = false_negative_rate[terrain]\n",
        "        ## Cost from current cell to first cell (i,j)\n",
        "        cost_1 = distance_from_current_to_first/ (2 * a) + 1 \n",
        "        p_1 = 1 - (belief_map[first_cell]*(1 - false_negative_cell_opened))\n",
        "        \n",
        "        min_cost_so_far = float('inf')\n",
        "        for m in range(a):\n",
        "          for n in range(a):\n",
        "            if(m!=i or n!=j) and (m!=current_cell[0] or n!=current_cell[1]):\n",
        "              temp_belief_map = np.full((a,a), 0)\n",
        "              temp_belief_map = update_belief(environment, belief_map, first_cell, false_negative_rate) \n",
        "              second_cell = (m,n)\n",
        "              distance_from_first_to_second = (abs(i-m) + abs(j-n))\n",
        "              terrain = np.int(env_grid[second_cell]/5)-1\n",
        "              false_negative_cell_opened = false_negative_rate[terrain]\n",
        "              ## Expected cost from second cell to any other future step\n",
        "              temp_belief_map_2 = update_belief(environment, temp_belief_map, second_cell, false_negative_rate)\n",
        "              # min_cell, min_actions, min_cost = compute_cost_one_step(environment, temp_belief_map_2, second_cell, false_negative_rate)\n",
        "              cost_2 = (distance_from_first_to_second/ (2 * a)) + 1 + (1 - (temp_belief_map[second_cell]*(1 - false_negative_cell_opened))) #*min1_cost\n",
        "\n",
        "              total_expected_cost = cost_1 + p_1*cost_2\n",
        "\n",
        "              if(min_cost_so_far > total_expected_cost):\n",
        "                min_cost_so_far = total_expected_cost\n",
        "                min_second_cell = second_cell\n",
        "\n",
        "        cost_matrix[(i, j)] = round(min_cost_so_far,2)\n",
        "        second_cells[i][j] = min_second_cell\n",
        "\n",
        "  min_first_cell = np.unravel_index(np.random.choice(np.flatnonzero(cost_matrix == cost_matrix.min())), cost_matrix.shape)\n",
        "  # print(\"Min_cost = \", cost_matrix[min_first_cell])\n",
        "  # print(\"First cell = \", min_first_cell )\n",
        "  # print(\"Second cell = \", second_cells[min_first_cell[0]][min_first_cell[1]])\n",
        "  # print(\"Cost Matrix:\")\n",
        "  # pp.pprint(cost_matrix)\n",
        "  # display_grid((cost_matrix, min_first_cell))\n",
        "  actions = compute_actions(current_cell, min_first_cell)\n",
        "  return min_first_cell, actions, min_cost_so_far\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXS6SHrn7Spb",
        "colab_type": "text"
      },
      "source": [
        "####Main agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPh2r5dJ7Oeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bonus_agent_rule_1(environment):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "\n",
        "  initial_belief = 1/(a*a)\n",
        "  belief_map = np.full((a,a), initial_belief)\n",
        "\n",
        "  total_actions = 0\n",
        "\n",
        "  ##number of neighbours map ##\n",
        "  neighbor_info_map = neighbor_information(a)\n",
        "\n",
        "  i = random.randint(0, a-1)\n",
        "  j = random.randint(0, a-1)\n",
        "  current_agent_location = (i,j)\n",
        "\n",
        "\n",
        "  while(True):\n",
        "    \n",
        "    is_target = search_cell(environment, current_agent_location)\n",
        "    \n",
        "\n",
        "    if(is_target):\n",
        "      \n",
        "      return total_actions\n",
        "    #failure\n",
        "    else:\n",
        "      \n",
        "      environment, target_not_in_terrain = tracker(environment)\n",
        "      belief_map = belief_updade_given_failure(belief_map, neighbor_info_map)\n",
        "      belief_map = belief_update_given_tracker_info(environment, belief_map, target_not_in_terrain)\n",
        "\n",
        "      new_agent_location = rule_1(belief_map)\n",
        "      total_actions = total_actions + compute_actions(current_agent_location, new_agent_location)\n",
        "      current_agent_location = new_agent_location\n",
        "\n",
        "  return total_actions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVsGFjIl67wD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bonus_agent_rule_2(environment):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "\n",
        "  initial_belief = 1/(a*a)\n",
        "  belief_map = np.full((a,a), initial_belief)\n",
        "\n",
        "  total_actions = 0\n",
        "  false_negative_rate = [0.1, 0.3, 0.7, 0.9]\n",
        "  ##number of neighbours map ##\n",
        "  neighbor_info_map = neighbor_information(a)\n",
        "\n",
        "  i = random.randint(0, a-1)\n",
        "  j = random.randint(0, a-1)\n",
        "  current_agent_location = (i,j)\n",
        "\n",
        "\n",
        "  while(True):\n",
        "    \n",
        "    is_target = search_cell(environment, current_agent_location)\n",
        "    \n",
        "\n",
        "    if(is_target):\n",
        "      \n",
        "      return total_actions\n",
        "    #failure\n",
        "    else:\n",
        "      \n",
        "      environment, target_not_in_terrain = tracker(environment)\n",
        "      belief_map = belief_updade_given_failure(belief_map, neighbor_info_map)\n",
        "      belief_map = belief_update_given_tracker_info(environment, belief_map, target_not_in_terrain)\n",
        "\n",
        "      new_agent_location = rule_2(environment, belief_map, false_negative_rate)\n",
        "      total_actions = total_actions + compute_actions(current_agent_location, new_agent_location)\n",
        "      current_agent_location = new_agent_location\n",
        "\n",
        "  return total_actions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoPODE0gBFxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bonus_agent_cost_1(environment):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "\n",
        "  initial_belief = 1/(a*a)\n",
        "  belief_map = np.full((a,a), initial_belief)\n",
        "  false_negative_rate = [0.1, 0.3, 0.7, 0.9]\n",
        "\n",
        "  total_actions = 1\n",
        "\n",
        "  ##number of neighbours map ##\n",
        "  neighbor_info_map = neighbor_information(a)\n",
        "\n",
        "  i = random.randint(0, a-1)\n",
        "  j = random.randint(0, a-1)\n",
        "  current_agent_location = (i,j)\n",
        "\n",
        "  trial = 0\n",
        "\n",
        "\n",
        "  while(True):\n",
        "\n",
        "    #if(trial%10 == 0):  print(\"Trial: \", trial)\n",
        "    trial = trial +1\n",
        "    is_target = search_cell(environment, current_agent_location)\n",
        "\n",
        "    if(is_target):\n",
        "      return total_actions\n",
        "    #failure\n",
        "    else:\n",
        "      \n",
        "      environment, target_not_in_terrain = tracker(environment)\n",
        "      belief_map = belief_updade_given_failure(belief_map, neighbor_info_map)\n",
        "      belief_map = belief_update_given_tracker_info(environment, belief_map, target_not_in_terrain)\n",
        "\n",
        "      current_agent_location, actions, min_cost_so_far = compute_cost_one_step(environment, belief_map, current_agent_location, false_negative_rate)\n",
        "      total_actions = total_actions + actions\n",
        "\n",
        "  return total_actions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXWFDWeFBJgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bonus_agent_cost_2(environment):\n",
        "\n",
        "  env_grid = environment[0]\n",
        "  a = env_grid.shape[0]\n",
        "\n",
        "  initial_belief = 1/(a*a)\n",
        "  belief_map = np.full((a,a), initial_belief)\n",
        "  false_negative_rate = [0.1, 0.3, 0.7, 0.9]\n",
        "\n",
        "  total_actions = 1\n",
        "\n",
        "  ##number of neighbours map ##\n",
        "  neighbor_info_map = neighbor_information(a)\n",
        "\n",
        "  i = random.randint(0, a-1)\n",
        "  j = random.randint(0, a-1)\n",
        "  current_agent_location = (i,j)\n",
        "\n",
        "  trial = 0\n",
        "\n",
        "\n",
        "  while(True):\n",
        "\n",
        "    #if(trial%10 == 0):  print(\"Trial: \", trial)\n",
        "    trial = trial +1\n",
        "    is_target = search_cell(environment, current_agent_location)\n",
        "\n",
        "    if(is_target):\n",
        "      return total_actions\n",
        "    #failure\n",
        "    else:\n",
        "      \n",
        "      environment, target_not_in_terrain = tracker(environment)\n",
        "      belief_map = belief_updade_given_failure(belief_map, neighbor_info_map)\n",
        "      belief_map = belief_update_given_tracker_info(environment, belief_map, target_not_in_terrain)\n",
        "\n",
        "      current_agent_location, actions, min_cost_so_far = simplified_two_step_cost(environment, belief_map, current_agent_location, false_negative_rate)\n",
        "      total_actions = total_actions + actions\n",
        "\n",
        "  return total_actions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xslOh77-7fHN",
        "colab_type": "code",
        "outputId": "f39c8059-2e46-4953-b98f-d9a40e6687a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "## Call to the agent #\n",
        "\n",
        "a = 5\n",
        "environment = generate_environment(a)\n",
        "bonus_agent_rule_1(environment)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa9qjNJZ7hfa",
        "colab_type": "text"
      },
      "source": [
        "## Analysing the performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYM-SPGB7jo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analysis_rule_1_2(a, n):\n",
        "\n",
        "  sum_searches_rule_1 = 0\n",
        "  sum_searches_rule_2 = 0\n",
        "  for i in range(n):\n",
        "\n",
        "    print(\"Trial: \", i)\n",
        "    environment = generate_environment(a)\n",
        "    sum_searches_rule_1 = sum_searches_rule_1 + bonus_agent_rule_1(environment)\n",
        "    sum_searches_rule_2 = sum_searches_rule_2 + bonus_agent_rule_2(environment)\n",
        "\n",
        "  avg_searches_rule_1 = sum_searches_rule_1/n\n",
        "  avg_searches_rule_2 = sum_searches_rule_2/n\n",
        "  print(avg_searches_rule_1)\n",
        "  print(avg_searches_rule_2)\n",
        "\n",
        "  plt.bar([\"Rule 1\", \"Rule 2\"], [avg_searches_rule_1, avg_searches_rule_2])\n",
        "  plt.ylabel(\"Average no. of searches\")\n",
        "  fig1 = plt.gcf()\n",
        "  plt.show()\n",
        "  fig1.savefig('bonus_rule_1_2.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl8ZwQd3BPXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analysis_cost_1_2(a, n):\n",
        "\n",
        "  sum_searches_1 = 0\n",
        "  sum_searches_2 = 0\n",
        "\n",
        "  for i in range(n):\n",
        "\n",
        "    environment = generate_environment(a)\n",
        "    sum_searches_1 = sum_searches_1 + bonus_agent_cost_1(environment)\n",
        "    sum_searches_2 = sum_searches_2 + bonus_agent_cost_2(environment)\n",
        "\n",
        "  avg_searches_1 = sum_searches_1/n\n",
        "  avg_searches_2 = sum_searches_2/n\n",
        "\n",
        "  print(avg_searches_1)\n",
        "  print(avg_searches_2)\n",
        "\n",
        "  plt.bar([\"Cost 1\", \"Cost 2\"], [avg_searches_1, avg_searches_2])\n",
        "  plt.ylabel(\"Average no. of searches\")\n",
        "  fig1 = plt.gcf()\n",
        "  plt.show()\n",
        "  fig1.savefig('bonus_cost_1_2.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ard7CBWQBPfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def analysis_cost_rule(a, n):\n",
        "\n",
        "  sum_searches_1 = 0\n",
        "  sum_searches_2 = 0\n",
        "  sum_searches_rule_1 = 0\n",
        "  sum_searches_rule_2 = 0\n",
        " \n",
        "\n",
        "  for i in range(n):\n",
        "\n",
        "    print(\"trial:\", i)\n",
        "\n",
        "    environment = generate_environment(a)\n",
        "    sum_searches_1 = sum_searches_1 + bonus_agent_cost_1(environment)\n",
        "    sum_searches_2 = sum_searches_2 + bonus_agent_cost_2(environment)\n",
        "    sum_searches_rule_1 = sum_searches_rule_1 + bonus_agent_rule_1(environment)\n",
        "    sum_searches_rule_2 = sum_searches_rule_2 + bonus_agent_rule_2(environment)\n",
        "\n",
        "    avg_searches_1 = sum_searches_1/(i+1)\n",
        "    avg_searches_2 = sum_searches_2/(i+1)\n",
        "    avg_searches_rule_1 = sum_searches_rule_1/(i+1)\n",
        "    avg_searches_rule_2 = sum_searches_rule_2/(i+1)\n",
        "\n",
        "    df = pd.DataFrame(columns = ['Cost 1', 'Cost 2', 'Rule 1', 'Rule 2'] , index = np.arange(0,1,1))\n",
        "    data = [avg_searches_1, avg_searches_2, avg_searches_rule_1, avg_searches_rule_2]\n",
        "    df.loc[-1] = data\n",
        "    df.index = df.index + 1\n",
        "    df = df.sort_index()\n",
        "    df.to_csv('Cost_Rule_Bonus.csv')\n",
        "\n",
        "\n",
        "    pal = sns.color_palette(\"Greens_d\", len(data))\n",
        "\n",
        "    rank = df.loc[0].argsort().argsort()  \n",
        "    sns.barplot([\"Cost 1\", \"Cost 2\", \"Rule 1\", \"Rule 2\"], data,  palette=np.array(pal[::-1])[rank])\n",
        "    plt.ylabel(\"Average no. of actions\")\n",
        "    fig1 = plt.gcf()\n",
        "    #plt.show()\n",
        "    fig1.savefig('Cost_Rule_Bonus.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz5eRPwQBPnP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "524622be-9838-4348-dc7b-a423ca5ae915"
      },
      "source": [
        "a = 5\n",
        "n = 2\n",
        "environment = generate_environment(a)\n",
        "analysis_cost_rule(a, n)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trial: 0\n",
            "trial: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD4CAYAAAAD6PrjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIiISpJCRERUkhQiIqLy/wHvKIbzq8wk4QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}